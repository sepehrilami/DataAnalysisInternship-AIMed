{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNLybZzJxi1fIfyjyf603nB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kFpTlEIfhv3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "import re\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_X79SXaihTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalize every sentence\n",
        "def normalize_sentence(df, lang):\n",
        "    sentence = df[lang].str\n",
        "    sentence = sentence.encode('utf-8', errors='ignore').str.decode('utf-8')\n",
        "    return sentence\n",
        "\n",
        "def read_sentence(df, first, second):\n",
        "   sentence1 = normalize_sentence(df, first)\n",
        "   sentence2 = normalize_sentence(df, second)\n",
        "   return sentence1, sentence2\n",
        "\n",
        "def read_file(loc, first, second):\n",
        "   df = pd.read_csv(loc, delimiter=' , ', header=None, names=[first, second])\n",
        "   return df\n",
        "\n",
        "def process_data(first, second):\n",
        "    df = read_file('/content/ferdosi.txt', first, second)\n",
        "    print(\"Read %s sentence pairs\" % len(df))\n",
        "    sentence1, sentence2 = read_sentence(df, first, second)\n",
        "\n",
        "    source = Lang()\n",
        "    target = Lang()\n",
        "    pairs = []\n",
        "\n",
        "    for i in range(len(df)):\n",
        "        if len(sentence1[i].split(' ')) < MAX_LENGTH and len(sentence2[i].split(' ')) < MAX_LENGTH:\n",
        "            full = [sentence1[i], sentence2[i]]\n",
        "            source.addSentence(sentence1[i])\n",
        "            target.addSentence(sentence2[i])\n",
        "            pairs.append(full)\n",
        "\n",
        "    return source, target, pairs"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkbVbKofgSY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 15\n",
        "\n",
        "#initialize Lang Class\n",
        "class Lang:\n",
        "    def __init__(self):\n",
        "        #initialize containers to hold the words and corresponding index\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    #split a sentence into words and add it to the container\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    #If the word is not in the container, the word will be added to it, \n",
        "    #else, update the word counter\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muo-hbS5gq1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def indexesFromSentence(lang, sentence):\n",
        "   return [lang.word2index[word] for word in sentence.split(' ')]\n",
        "\n",
        "def tensorFromSentence(lang, sentence):\n",
        "   indexes = indexesFromSentence(lang, sentence)\n",
        "   indexes.append(EOS_token)\n",
        "   return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
        "\n",
        "def tensorsFromPair(source, target, pair):\n",
        "   input_tensor = tensorFromSentence(source, pair[0])\n",
        "   target_tensor = tensorFromSentence(target, pair[1])\n",
        "   return (input_tensor, target_tensor)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRv_FcdfgUll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jL1rcx3guLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "   def __init__(self, input_dim, hidden_dim, embbed_dim, num_layers):\n",
        "       super(Encoder, self).__init__()\n",
        "      \n",
        "       #set the encoder input dimesion , embbed dimesion, hidden dimesion, and number of layers \n",
        "       self.input_dim = input_dim\n",
        "       self.embbed_dim = embbed_dim\n",
        "       self.hidden_dim = hidden_dim\n",
        "       self.num_layers = num_layers\n",
        "\n",
        "       #initialize the embedding layer with input and embbed dimention\n",
        "       self.embedding = nn.Embedding(input_dim, self.embbed_dim)\n",
        "       #intialize the GRU to take the input dimetion of embbed, and output dimention of hidden and\n",
        "       #set the number of GRU layers\n",
        "       self.GRU = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "              \n",
        "   def forward(self, src):\n",
        "      \n",
        "       embedded = self.embedding(src).view(1,1,-1)\n",
        "       outputs, hidden = self.GRU(embedded)\n",
        "       return outputs, hidden"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dj5JvJlg5kD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, embbed_dim, num_layers):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        #set the encoder output dimension, embed dimension, hidden dimension, and number of layers \n",
        "        self.embbed_dim = embbed_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.dropout = torch.nn.Dropout(0.1)\n",
        "\n",
        "        # initialize every layer with the appropriate dimension. For the decoder layer, it will consist of an embedding, GRU, a Linear layer and a Log softmax activation function.\n",
        "        self.embedding = nn.Embedding(output_dim, self.embbed_dim)\n",
        "        self.GRU = nn.GRU(self.embbed_dim, self.hidden_dim, num_layers=self.num_layers)\n",
        "        self.out = nn.Linear(self.hidden_dim, output_dim)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "      \n",
        "    def forward(self, input, hidden):\n",
        "        \n",
        "\n",
        "        # reshape the input to (1, batch_size)\n",
        "        input = input.view(1, -1)\n",
        "        embedded = self.embedding(input)\n",
        "        embedded = self.dropout(embedded)\n",
        "        output, hidden = self.GRU(embedded, hidden)       \n",
        "        prediction = self.softmax(self.out(output[0]))\n",
        "      \n",
        "        return prediction, hidden\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McKPloGvg877",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "   def __init__(self, encoder, decoder, device, MAX_LENGTH=MAX_LENGTH):\n",
        "        super().__init__()\n",
        "      \n",
        "        #initialize the encoder and decoder\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "     \n",
        "   def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
        "\n",
        "        input_length = source.size(0) #get the input length (number of words in sentence)\n",
        "        target_length = target.shape[0]\n",
        "        batch_size = target.shape[1] \n",
        "        vocab_size = self.decoder.output_dim\n",
        "      \n",
        "        #initialize a variable to hold the predicted outputs\n",
        "        outputs = torch.zeros(target_length, batch_size, vocab_size).to(self.device)\n",
        "\n",
        "        #encode every word in a sentence\n",
        "        encoder_output, encoder_hidden = self.encoder(source)\n",
        "\n",
        "        #use the encoder’s hidden layer as the decoder hidden\n",
        "        decoder_hidden = encoder_hidden.to(device)\n",
        "    \n",
        "        #add a token before the first predicted word\n",
        "        decoder_input = torch.tensor([SOS_token], device=device)  # SOS\n",
        "\n",
        "        #topk is used to get the top K value over a list\n",
        "        #predict the output word from the current target word. If we enable the teaching force,  then the #next decoder input is the next word, else, use the decoder output highest value. \n",
        "\n",
        "        for t in range(target_length):   \n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "            outputs[t] = decoder_output\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "            topv, topi = decoder_output.topk(1)\n",
        "            input = (target[t] if teacher_force else topi)\n",
        "            if(teacher_force == False and input.item() == EOS_token):\n",
        "                break\n",
        "\n",
        "        return outputs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBqzMoZOgyXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_forcing_ratio = 0.5\n",
        "\n",
        "def clacModel(model, input_tensor, target_tensor, model_optimizer, criterion):\n",
        "    \n",
        "    model_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    loss = 0\n",
        "    epoch_loss = 0\n",
        "\n",
        "    output = model(input_tensor, target_tensor)\n",
        "\n",
        "    num_iter = output.size(0)\n",
        "\n",
        "    #calculate the loss from a predicted sentence with the expected result\n",
        "    for ot in range(num_iter):\n",
        "        loss += criterion(output[ot], target_tensor[ot])\n",
        "\n",
        "    loss.backward()\n",
        "    model_optimizer.step()\n",
        "    epoch_loss = loss.item() / num_iter\n",
        "\n",
        "    return epoch_loss\n",
        "\n",
        "def trainModel(model, source, target, pairs, num_iteration=20000):\n",
        "    model.train()\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.NLLLoss()\n",
        "    total_loss_iterations = 0\n",
        "    loss = 0\n",
        "    training_pairs = [tensorsFromPair(source, target, random.choice(pairs)) for i in range(num_iteration)]\n",
        "    \n",
        "    print(\"num of iterations is\", num_iteration)\n",
        "    for iter in range(1, num_iteration + 1):\n",
        "        training_pair = training_pairs[iter - 1]\n",
        "        input_tensor = training_pair[0]\n",
        "        target_tensor = training_pair[1]\n",
        "\n",
        "        total_loss_iterations += clacModel(model, input_tensor, target_tensor, optimizer, criterion)\n",
        "        loss += total_loss_iterations\n",
        "        \n",
        "        if iter % 100 == 0:\n",
        "            avarage_loss = total_loss_iterations / 50\n",
        "            total_loss_iterations = 0\n",
        "            print('%d %.4f' % (iter, avarage_loss))\n",
        "            print(f'[Train] loss: {loss / (i + 1):.3e}')\n",
        "        \n",
        "            \n",
        "    torch.save(model.state_dict(), 'mytraining.pt')\n",
        "    return model , (loss / iter)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_ZSshHciekK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, input_lang, output_lang, sentences, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentences[0])\n",
        "        output_tensor = tensorFromSentence(output_lang, sentences[1])\n",
        "    \n",
        "        decoded_words = []\n",
        "    \n",
        "        output = model(input_tensor, output_tensor)\n",
        "    \n",
        "        for ot in range(output.size(0)):\n",
        "            topv, topi = output[ot].topk(1)\n",
        "\n",
        "            if topi[0].item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            else:\n",
        "                decoded_words.append(output_lang.index2word[topi[0].item()])\n",
        "    return decoded_words\n",
        "\n",
        "def evaluateRandomly(model, source, target, pairs, n=5):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print(\"source {}\".format(pair[0]))        \n",
        "        output_words = evaluate(model, source, target, pair)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print(\"target {}\".format(pair[1]))\n",
        "        print(\"predicted {}\".format(output_sentence))\n",
        "        \n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0mUa5Hbikn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "341e7a67-b9bf-4893-f01e-e6b2ffeb2536"
      },
      "source": [
        "source, target, pairs = process_data('first', 'second')\n",
        "\n",
        "randomize = random.choice(pairs)\n",
        "print('random sentence {}'.format(randomize))\n",
        "\n",
        "#print number of words\n",
        "input_size = source.n_words\n",
        "output_size = target.n_words\n",
        "print('Input : {} Output : {}'.format(input_size, output_size))\n",
        "\n",
        "embed_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_iteration = 1000\n",
        "\n",
        "#create encoder-decoder model\n",
        "encoder = Encoder(input_size, hidden_size, embed_size, num_layers)\n",
        "decoder = Decoder(output_size, hidden_size, embed_size, num_layers)\n",
        "\n",
        "model = Seq2Seq(encoder, decoder, device).to(device)\n",
        "\n",
        "#print model \n",
        "print(encoder)\n",
        "print(decoder)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Read 49609 sentence pairs\n",
            "random sentence ['که ما سربسر مر تو را بنده ایم', 'بفرمان و رایت سرافگنده ایم']\n",
            "Input : 12458 Output : 13071\n",
            "Encoder(\n",
            "  (embedding): Embedding(12458, 256)\n",
            "  (GRU): GRU(256, 512)\n",
            ")\n",
            "Decoder(\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (embedding): Embedding(13071, 256)\n",
            "  (GRU): GRU(256, 512)\n",
            "  (out): Linear(in_features=512, out_features=13071, bias=True)\n",
            "  (softmax): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5RLjVJA5VYU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9868b9a1-d2f3-4d69-8350-49fced02f6e6"
      },
      "source": [
        "from time import time\n",
        "\n",
        "epochs = 3\n",
        "\n",
        "for i in range(epochs):\n",
        "\n",
        "    start_time = time()\n",
        "    \n",
        "    model, train_loss = trainModel(model, source, target, pairs, num_iteration)\n",
        "    evaluateRandomly(model, source, target, pairs)\n",
        "\n",
        "\n",
        "    print(f'\\tTrain Loss: {train_loss:.3e} | Train PPL: {np.exp(train_loss):.3e}')\n",
        "\n",
        "    end_time = time()\n",
        "\n",
        "    print(\"ended in: \", end_time - start_time, \"sec\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num of iterations is 1000\n",
            "100 12.4936\n",
            "[Train] loss: 3.308e+04\n",
            "200 11.0764\n",
            "[Train] loss: 6.035e+04\n",
            "300 11.0905\n",
            "[Train] loss: 8.793e+04\n",
            "400 11.2645\n",
            "[Train] loss: 1.165e+05\n",
            "500 11.7843\n",
            "[Train] loss: 1.466e+05\n",
            "600 11.4418\n",
            "[Train] loss: 1.759e+05\n",
            "700 11.3824\n",
            "[Train] loss: 2.047e+05\n",
            "800 11.7607\n",
            "[Train] loss: 2.342e+05\n",
            "900 12.1450\n",
            "[Train] loss: 2.653e+05\n",
            "1000 11.7166\n",
            "[Train] loss: 2.947e+05\n",
            "source ز بیژن مگر اگهی یابما\n",
            "['ز بیژن مگر اگهی یابما', 'بدین کار هشیار بشتابما']\n",
            "target بدین کار هشیار بشتابما\n",
            "predicted به به هر هر <EOS>\n",
            "source هم اکنون تن کشتگان را بخاک\n",
            "['هم اکنون تن کشتگان را بخاک', 'بپوشید جایی که باشد مغاک']\n",
            "target بپوشید جایی که باشد مغاک\n",
            "predicted به به هر <EOS>\n",
            "source جهانجوی را دید جامی به دست\n",
            "['جهانجوی را دید جامی به دست', 'نگهبان اسپان همه خفته مست']\n",
            "target نگهبان اسپان همه خفته مست\n",
            "predicted به به هر <EOS>\n",
            "source مرا ناگهان در عماری نشاند\n",
            "['مرا ناگهان در عماری نشاند', 'بران خوب چهره فسونی بخواند']\n",
            "target بران خوب چهره فسونی بخواند\n",
            "predicted به به هر <EOS>\n",
            "source به تو داد یک روز نوبت پدر\n",
            "['به تو داد یک روز نوبت پدر', 'سزد گر ترا نوبت اید بسر']\n",
            "target سزد گر ترا نوبت اید بسر\n",
            "predicted به به هر هر <EOS>\n",
            "\tTrain Loss: 2.947e+02 | Train PPL: 1.017e+128\n",
            "ended in:  294.6421904563904 sec\n",
            "num of iterations is 1000\n",
            "100 11.2453\n",
            "[Train] loss: 1.406e+04\n",
            "200 11.2967\n",
            "[Train] loss: 2.899e+04\n",
            "300 11.4939\n",
            "[Train] loss: 4.389e+04\n",
            "400 11.2486\n",
            "[Train] loss: 5.808e+04\n",
            "500 11.0678\n",
            "[Train] loss: 7.182e+04\n",
            "600 11.2588\n",
            "[Train] loss: 8.559e+04\n",
            "700 12.1112\n",
            "[Train] loss: 1.008e+05\n",
            "800 11.5068\n",
            "[Train] loss: 1.148e+05\n",
            "900 11.1844\n",
            "[Train] loss: 1.286e+05\n",
            "1000 11.6828\n",
            "[Train] loss: 1.433e+05\n",
            "source نود بار و سه بار کرده شمار\n",
            "['نود بار و سه بار کرده شمار', 'به ایران درم بد هزاران هزار']\n",
            "target به ایران درم بد هزاران هزار\n",
            "predicted که که و <EOS>\n",
            "source ز گفتار ویران نگردد جهان\n",
            "['ز گفتار ویران نگردد جهان', 'بگو انچ رایت بود در نهان']\n",
            "target بگو انچ رایت بود در نهان\n",
            "predicted که که و <EOS>\n",
            "source بپیمان که از هر دو روی سپاه\n",
            "['بپیمان که از هر دو روی سپاه', 'بیاری نیاید کسی کینه خواه']\n",
            "target بیاری نیاید کسی کینه خواه\n",
            "predicted که که و <EOS>\n",
            "source ز چین نزد شاپور شد بار خواست\n",
            "['ز چین نزد شاپور شد بار خواست', 'به پیغمبری شاه را یار خواست']\n",
            "target به پیغمبری شاه را یار خواست\n",
            "predicted که که و <EOS>\n",
            "source ستایش همی کرد برکردگار\n",
            "['ستایش همی کرد برکردگار', 'ازان شادمان گردش روزگار']\n",
            "target ازان شادمان گردش روزگار\n",
            "predicted که که و <EOS>\n",
            "\tTrain Loss: 2.865e+02 | Train PPL: 2.783e+124\n",
            "ended in:  299.80426383018494 sec\n",
            "num of iterations is 1000\n",
            "100 11.4635\n",
            "[Train] loss: 9.672e+03\n",
            "200 11.1015\n",
            "[Train] loss: 1.879e+04\n",
            "300 10.3653\n",
            "[Train] loss: 2.788e+04\n",
            "400 11.5245\n",
            "[Train] loss: 3.764e+04\n",
            "500 11.8210\n",
            "[Train] loss: 4.743e+04\n",
            "600 11.6663\n",
            "[Train] loss: 5.744e+04\n",
            "700 11.2049\n",
            "[Train] loss: 6.679e+04\n",
            "800 11.0991\n",
            "[Train] loss: 7.634e+04\n",
            "900 11.2937\n",
            "[Train] loss: 8.565e+04\n",
            "1000 11.8797\n",
            "[Train] loss: 9.581e+04\n",
            "source براهی که هرگز نرفتی مپوی\n",
            "['براهی که هرگز نرفتی مپوی', 'بر شاه خیره مبر ابروی']\n",
            "target بر شاه خیره مبر ابروی\n",
            "predicted که که و و <EOS>\n",
            "source چو بشنید موبد بشد نزد شاه\n",
            "['چو بشنید موبد بشد نزد شاه', 'بدو داد یکسر پیام سپاه']\n",
            "target بدو داد یکسر پیام سپاه\n",
            "predicted که که و و <EOS>\n",
            "source درخت و برادر بهم بر بدوخت\n",
            "['درخت و برادر بهم بر بدوخت', 'به هنگام رفتن دلش برفروخت']\n",
            "target به هنگام رفتن دلش برفروخت\n",
            "predicted که که و و <EOS>\n",
            "source چو بشنید بهرام و اندیشه کرد\n",
            "['چو بشنید بهرام و اندیشه کرد', 'دلش گشت پر درد و رخساره زرد']\n",
            "target دلش گشت پر درد و رخساره زرد\n",
            "predicted که که و و <EOS>\n",
            "source چو ان نامه نزدیک خسرو رسید\n",
            "['چو ان نامه نزدیک خسرو رسید', 'زپیوستن اگاهی نو رسید']\n",
            "target زپیوستن اگاهی نو رسید\n",
            "predicted که که و و <EOS>\n",
            "\tTrain Loss: 2.874e+02 | Train PPL: 6.671e+124\n",
            "ended in:  301.2089273929596 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOw3w_lLY-WX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}