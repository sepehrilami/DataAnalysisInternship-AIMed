{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PLS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sepehrilami/DataScienceInternship-AIMed/blob/master/PLS/PLS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt2LGmI0ePmv"
      },
      "source": [
        "#  Importing!\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pylab as plt\n",
        "from skimage.transform import resize\n",
        "from time import time\n",
        "\n",
        "# %matplotlib inline\n",
        "# from __future__ import print_function\n",
        "# from IPython.display import HTML\n",
        "# import torch.nn.parallel\n",
        "# import torch.backends.cudnn as cudnn\n",
        "# import nibabel as nib\n",
        "# import torch.utils.data\n",
        "# import torchvision.datasets as dset\n",
        "# import torchvision.transforms as transforms\n",
        "# import torchvision.utils as vutils"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofren4nceaOB",
        "outputId": "af91e56e-5656-430e-e081-1ba041811f0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Requird for reading mhd format\n",
        "!pip install SimpleITK\n",
        "import SimpleITK as sitk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.6/dist-packages (2.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YVOxnbhedtA",
        "outputId": "41144bc2-6497-42a3-92ea-802feafe8b03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Reading 3 samples from VESSEL12 dataset\n",
        "!wget https://www.dropbox.com/sh/1j2x17k8y18k3l6/AACkAc6bCEqYVXBdODFo6Iqya/VESSEL12_ExampleScans.tar.bz2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-02 06:58:49--  https://www.dropbox.com/sh/1j2x17k8y18k3l6/AACkAc6bCEqYVXBdODFo6Iqya/VESSEL12_ExampleScans.tar.bz2\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/raw/1j2x17k8y18k3l6/AACkAc6bCEqYVXBdODFo6Iqya/VESSEL12_ExampleScans.tar.bz2 [following]\n",
            "--2020-11-02 06:58:49--  https://www.dropbox.com/sh/raw/1j2x17k8y18k3l6/AACkAc6bCEqYVXBdODFo6Iqya/VESSEL12_ExampleScans.tar.bz2\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca2be0d20cedf41948ec380bcad.dl.dropboxusercontent.com/cd/0/inline/BCZlfq0L51fE40x4RIMJpuA0PaZaIIQ8Ykuq1vtwoenO6oDftBRQwj_Bjgp0ubQLtukIpQifSnBhcMkjPNlOKiF9BuSD0Bad3IxeUILhi3HhGw/file# [following]\n",
            "--2020-11-02 06:58:50--  https://uca2be0d20cedf41948ec380bcad.dl.dropboxusercontent.com/cd/0/inline/BCZlfq0L51fE40x4RIMJpuA0PaZaIIQ8Ykuq1vtwoenO6oDftBRQwj_Bjgp0ubQLtukIpQifSnBhcMkjPNlOKiF9BuSD0Bad3IxeUILhi3HhGw/file\n",
            "Resolving uca2be0d20cedf41948ec380bcad.dl.dropboxusercontent.com (uca2be0d20cedf41948ec380bcad.dl.dropboxusercontent.com)... 162.125.67.15, 2620:100:6021:15::a27d:410f\n",
            "Connecting to uca2be0d20cedf41948ec380bcad.dl.dropboxusercontent.com (uca2be0d20cedf41948ec380bcad.dl.dropboxusercontent.com)|162.125.67.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BCan9aKDGFyN-AIn5ui9nV15O71NzZfUolorimpIzgucWKAVe3Bci_EopACErj8-nJJMvzN38Rb2o2KmUER6IUicBguTvGPBDPqfUzZtwL9scDUSUNEIEA6a73c116g9AO7U0ttOM1X6S1PZsoGL-vWdjF3G9lWA_OnXWMN-qL6RwKMK21rGJSe2sBKpYjxzzZ3GGR6V-Nkd39RHK7QBPDW72FFtUMpd0dHCRQzUVaG_zU_DUo88ocu52MjdGc9rpPbSkRaw0ljpZh70l5KnF2lSeMaQN6ypfb7t_HPkbus6Uj_aakiHzkbKJa4pxFcJ5YhvNGFED_d_Z0lzYCrKxp7_/file [following]\n",
            "--2020-11-02 06:58:51--  https://uca2be0d20cedf41948ec380bcad.dl.dropboxusercontent.com/cd/0/inline2/BCan9aKDGFyN-AIn5ui9nV15O71NzZfUolorimpIzgucWKAVe3Bci_EopACErj8-nJJMvzN38Rb2o2KmUER6IUicBguTvGPBDPqfUzZtwL9scDUSUNEIEA6a73c116g9AO7U0ttOM1X6S1PZsoGL-vWdjF3G9lWA_OnXWMN-qL6RwKMK21rGJSe2sBKpYjxzzZ3GGR6V-Nkd39RHK7QBPDW72FFtUMpd0dHCRQzUVaG_zU_DUo88ocu52MjdGc9rpPbSkRaw0ljpZh70l5KnF2lSeMaQN6ypfb7t_HPkbus6Uj_aakiHzkbKJa4pxFcJ5YhvNGFED_d_Z0lzYCrKxp7_/file\n",
            "Reusing existing connection to uca2be0d20cedf41948ec380bcad.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 313639176 (299M) [application/octet-stream]\n",
            "Saving to: ‘VESSEL12_ExampleScans.tar.bz2’\n",
            "\n",
            "VESSEL12_ExampleSca 100%[===================>] 299.11M  33.3MB/s    in 10s     \n",
            "\n",
            "2020-11-02 06:59:02 (28.7 MB/s) - ‘VESSEL12_ExampleScans.tar.bz2’ saved [313639176/313639176]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQUlpJhPegK2"
      },
      "source": [
        "#Unzip samples\n",
        "!tar xf VESSEL12_ExampleScans.tar.bz2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpr1HAWnejIR"
      },
      "source": [
        "def read_mhd(file):\n",
        "    return sitk.GetArrayFromImage(sitk.ReadImage(file, sitk.sitkFloat32))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S4vfmCpelWt"
      },
      "source": [
        "vessel12_21 = read_mhd(\"Scans/VESSEL12_21.mhd\")\n",
        "vessel12_21_mask = read_mhd(\"Lungmasks/VESSEL12_21.mhd\")\n",
        "vessel12_22 = read_mhd(\"Scans/VESSEL12_22.mhd\")\n",
        "vessel12_22_mask = read_mhd(\"Lungmasks/VESSEL12_22.mhd\")\n",
        "vessel12_23 = read_mhd(\"Scans/VESSEL12_23.mhd\")\n",
        "vessel12_23_mask = read_mhd(\"Lungmasks/VESSEL12_23.mhd\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMbmW5D-enkM",
        "outputId": "287fed68-96ed-4460-af17-66cf31f86b49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vessel12_23_mask.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(418, 512, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6wZrxsdep0W"
      },
      "source": [
        "def draw(images, columns=4):\n",
        "    rows = int(np.ceil(images.shape[0] / columns))\n",
        "    max_size = 20\n",
        "    \n",
        "    width = max(columns * 5, max_size)\n",
        "    height = width * rows // columns\n",
        "\n",
        "    plt.figure(figsize=(width, height))\n",
        "    plt.gray()\n",
        "    plt.subplots_adjust(0,0,1,1,0.01,0.01)\n",
        "    for i in range(images.shape[0]):\n",
        "        plt.subplot(rows,columns,i+1), plt.imshow(images[i]), plt.axis('off')\n",
        "        # use plt.savefig(...) here if you want to save the images as .jpg, e.g.,\n",
        "    plt.show()\n",
        "\n",
        "def draw_masked(images, masks, columns=4):\n",
        "    assert images.shape == masks.shape\n",
        "    \n",
        "    rows = int(np.ceil(images.shape[0] / columns))\n",
        "    max_size = 20\n",
        "    \n",
        "    width = min(columns * 5, max_size)\n",
        "    height = width * rows // columns\n",
        "\n",
        "    fig = plt.figure(figsize=(width, height))\n",
        "    plt.gray()\n",
        "    plt.subplots_adjust(0,0,1,1,0.01,0.01)\n",
        "    \n",
        "    X, Y = np.meshgrid(np.arange(masks.shape[1]), np.arange(masks.shape[2]))\n",
        "    \n",
        "    for i in range(images.shape[0]):\n",
        "        ax = fig.add_subplot(rows,columns,i+1)\n",
        "        if masks[i].sum() > 0:\n",
        "            ax.contour(X, Y, masks[i], 1, colors='red', linewidths=0.5)\n",
        "        ax.imshow(images[i], origin='lower', cmap='gray')\n",
        "        plt.axis('off')\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq2yT5YHer8p"
      },
      "source": [
        "# custom weights initialization\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.01)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.01)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITK5VjD7ev4t"
      },
      "source": [
        "class DSconv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, DSkernel, depth_stride, DSstride, DSpadding, dilation=1):\n",
        "    super(DSconv, self).__init__()\n",
        "\n",
        "    self.dsconv = nn.Sequential(\n",
        "        #Input is 10, 512, 512\n",
        "\n",
        "        nn.Conv3d(in_channels, in_channels, DSkernel, depth_stride, DSpadding, dilation, groups = in_channels),\n",
        "\n",
        "        nn.BatchNorm3d(in_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv3d(in_channels, out_channels, 1 ,DSstride, 0, dilation),\n",
        "        nn.BatchNorm3d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    # print(\"dsconv shape of input:\", input.shape)  \n",
        "    return self.dsconv(input)\n",
        "\n",
        "\n",
        "class DRDB(nn.Module):\n",
        "      def __init__(self, in_channels, DRDBpadding):\n",
        "        super(DRDB, self).__init__()\n",
        "        \n",
        "        DSkernel = 3\n",
        "        DSstride = 1\n",
        "        DSpadding = DRDBpadding\n",
        "        self.conv_1 = DSconv(in_channels, in_channels, 3, 1, DSstride, 1, 1)\n",
        "        self.conv_2 = DSconv(in_channels * 2 , in_channels * 2, 3, 1, DSstride, 2, 2)\n",
        "        self.conv_3 = DSconv(in_channels * 4, in_channels * 4, 3, 1, DSstride, 3, 3)\n",
        "        self.conv_4 = DSconv(in_channels * 8, in_channels * 8, 3, 1, DSstride, 4, 4)\n",
        "        \n",
        "        self.final_conv = nn.Conv3d(in_channels * 16, in_channels, 1, DSstride, 0,bias=False)\n",
        "\n",
        "      def forward(self, DRDBinput):\n",
        "        first_convolved = self.conv_1(DRDBinput)\n",
        "        concat = torch.cat([first_convolved, DRDBinput], dim=1)\n",
        "        second_convolved = self.conv_2(concat)\n",
        "        concat = torch.cat([second_convolved, concat], dim=1)\n",
        "        third_convolved = self.conv_3(concat)\n",
        "        concat = torch.cat([third_convolved, concat], dim=1)\n",
        "        forth_convolved = self.conv_4(concat)\n",
        "        concat = torch.cat([forth_convolved, concat], dim=1)\n",
        "        xg0 = self.final_conv(concat)\n",
        "        return xg0 + DRDBinput"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytXb2mA3ewps"
      },
      "source": [
        "#Testing DRDB\n",
        "\n",
        "# test = torch.zeros(size= [1, 17, 10, 512, 512], device = 'cuda:0', dtype = torch.float16)\n",
        "# drdb = DRDB(17, 0)\n",
        "# drdb = drdb.to('cuda:0').half()\n",
        "# out = drdb(test)\n",
        "# out.shape"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lImBSDoe350"
      },
      "source": [
        "#Testing DSconv\n",
        "\n",
        "# test = torch.zeros(size= [1, 1, 8, 512, 512], device = 'cuda:0', dtype = torch.float16)\n",
        "# dsconv = nn.Sequential( DSconv(1, 16, 3, 2, 1, 1, dilation = 1),\n",
        "# DSconv(16, 16, 3, 2, 1, 1, dilation = 1),\n",
        "# DSconv(16, 1, 3, 2, 1, 1, dilation = 1))\n",
        "# dsconv = dsconv.to('cuda:0').half()\n",
        "# out = dsconv(test)\n",
        "# out.shape"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsLOEu-me1u1",
        "outputId": "b3e19858-3c99-4de1-c6eb-34081c5297e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1151"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH9A1blAe6eS"
      },
      "source": [
        "class PLSnet(nn.Module):\n",
        "  def __init__(self, DSkernel, DSstride, DSpadding, C):\n",
        "    super(PLSnet, self).__init__()\n",
        "\n",
        "    self.dsconvolve_1 = DSconv(1, 16, DSkernel, 2, DSstride, DSpadding)\n",
        "    self.dsconvolve_2 = DSconv(17, 64, DSkernel, 2, DSstride, DSpadding)\n",
        "    self.dsconvolve_3 = DSconv(65, 128, DSkernel, 2, DSstride, DSpadding)\n",
        "\n",
        "    self.mid_dsconvolve_1 = DSconv(17, 2*C, DSkernel, 1, DSstride, DSpadding, 1)\n",
        "    self.mid_dsconvolve_2 = DSconv(65, 2*C, DSkernel, 1, DSstride, DSpadding, 1)\n",
        "    \n",
        "    self.decoder_dsconvolve_1 = DSconv(129, 2*C, DSkernel, 1, DSstride, DSpadding, 1)\n",
        "    self.decoder_dsconvolve_2 = DSconv(4*C, 2*C, DSkernel, 1, DSstride, DSpadding, 1)\n",
        "    self.decoder_dsconvolve_3 = DSconv(4*C, 2*C, DSkernel, 1, DSstride, DSpadding, 1)\n",
        "\n",
        "    self.oneconv = nn.Conv3d(2*C, 1, 1, DSstride, 0)\n",
        "\n",
        "    DRDBpadding = DSpadding\n",
        "    self.drdb = DRDB(17, DRDBpadding)\n",
        "    self.drdbx2 = DRDB(65, DRDBpadding)\n",
        "    self.drdbx4 = DRDB(129, DRDBpadding)\n",
        "\n",
        "    self.TLupsample = nn.Upsample(scale_factor = 2, mode='trilinear')\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, InputImage, real_mask):\n",
        "\n",
        "    # resolution = 1 in encoder\n",
        "    DSconv_output = self.dsconvolve_1(InputImage)\n",
        "    # print(\"dsconv: \", DSconv_1.shape)\n",
        "    InputImage = nn.functional.interpolate(InputImage, scale_factor = 0.5, mode='trilinear')\n",
        "    # print(\"image: \", InputImage.shape)\n",
        "    concat_output = torch.cat([DSconv_output,InputImage], dim=1)\n",
        "    DRDB1_output = self.drdb(concat_output)\n",
        "    # resolution = 2 in encoder\n",
        "    DSconv_output = self.dsconvolve_2(DRDB1_output)\n",
        "    InputImage = nn.functional.interpolate(InputImage, scale_factor = 0.5, mode='trilinear')\n",
        "    concat_output = torch.cat([DSconv_output,InputImage], dim = 1)\n",
        "    DRDB2_output = self.drdbx2(self.drdbx2(concat_output))\n",
        "    # resolution = 3 in encoder\n",
        "    DSconv_output = self.dsconvolve_3(DRDB2_output)\n",
        "\n",
        "    InputImage = nn.functional.interpolate(InputImage, scale_factor = 0.5, mode = 'trilinear')\n",
        "    concat_output = torch.cat([DSconv_output,InputImage], dim = 1)\n",
        "\n",
        "    DSconv_output = self.decoder_dsconvolve_1(self.drdbx4(self.drdbx4(self.drdbx4(self.drdbx4(concat_output)))))\n",
        "    upsample_output = self.TLupsample(DSconv_output) \n",
        "    # resolution = 2 in decoder\n",
        "    DSconv_output = self.mid_dsconvolve_2(DRDB2_output)\n",
        "    concat_output = torch.cat([upsample_output, DSconv_output], dim = 1)\n",
        "    DSconv_output = self.decoder_dsconvolve_2(concat_output)\n",
        "    upsample_output = self.TLupsample(DSconv_output)\n",
        "    # resolution = 1 in decoder\n",
        "    DSconv_output = self.mid_dsconvolve_1(DRDB1_output)\n",
        "    concat_output = torch.cat([upsample_output, DSconv_output], dim = 1)\n",
        "    DSconv_output = self.decoder_dsconvolve_2(concat_output)\n",
        "    upsample_output = self.TLupsample(DSconv_output)\n",
        "    # resolution = 0 in decoder\n",
        "\n",
        "    output = self.oneconv(upsample_output)\n",
        "\n",
        "    predicted = self.sigmoid(output)\n",
        "\n",
        "    loss_output = F.binary_cross_entropy(predicted, real_mask.squeeze(dim = 1))    \n",
        "\n",
        "    return predicted, loss_output"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXZmo1NHfBHh"
      },
      "source": [
        "# in_channels = 10\n",
        "# out_channels = 256\n",
        "DSkernel = 3\n",
        "DSstride = 1\n",
        "DSpadding = 1\n",
        "\n",
        "C = 6   #number of classes\n",
        "\n",
        "model = PLSnet(DSkernel, DSstride, DSpadding, C)\n",
        "model = model.cuda()"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GL82GBPfD8r"
      },
      "source": [
        "optimizer = torch.optim.Adam(filter(\n",
        "    lambda p : p.requires_grad, model.parameters()),\n",
        "    lr = 0.001\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0x7HUnE5fZa"
      },
      "source": [
        "# output = torch.randn(1, 2, 8, 512, 512, dtype=torch.float32)\n",
        "# print(output.shape)\n",
        "# target = torch.empty(1, 8, 512, 512, dtype=torch.float32).random_(2)\n",
        "# print(target.shape)\n",
        "# print(F.cross_entropy(output, target))"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHXu6wm5fHv3"
      },
      "source": [
        "x_train = vessel12_21[200:208]\n",
        "y_train = vessel12_21_mask[200:208]\n",
        "x_val = vessel12_21[208:216]\n",
        "y_val = vessel12_21_mask[208:216]\n",
        "\n",
        "batch_size = 1\n",
        "batch_x_placeholder = torch.zeros(size= [batch_size, 1, x_train.shape[0], 512, 512], dtype = torch.float32, device = 'cuda:0')\n",
        "batch_y_placeholder = torch.zeros(size= [batch_size, 1, y_train.shape[0], 512, 512], dtype = torch.float32, device = 'cuda:0')\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "train_loss = np.zeros((batch_size * epochs,))\n",
        "val_loss = np.zeros((batch_size * epochs,))\n",
        "train_acc = np.zeros((batch_size * epochs,))\n",
        "val_acc = np.zeros((batch_size * epochs,))\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEDxVzxDfK7F",
        "outputId": "7f40086c-3f71-4866-d865-5c597fe73bc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "iters_per_epoch = int(np.ceil(1.0 * len(x_train) / batch_size))\n",
        "\n",
        "for e in range(epochs):\n",
        "    t_start = time()\n",
        "\n",
        "    model.train() # training phase\n",
        "\n",
        "    # shuffling\n",
        "    inds = np.arange(len(x_train))\n",
        "    np.random.shuffle(inds)\n",
        "\n",
        "    epoch_loss = 0\n",
        "    true_positive = 0\n",
        "\n",
        "\n",
        "    # iterating over the whole training set\n",
        "    for iter in range(iters_per_epoch):\n",
        "\n",
        "        batch_inds = inds[iter * batch_size: min(len(inds), (iter + 1) * batch_size)]\n",
        "        # print(batch_inds)\n",
        "\n",
        "        # reshaping placeholders\n",
        "        if len(batch_inds) != len(batch_x_placeholder):\n",
        "            batch_x_placeholder.resize_([len(batch_inds), 1, x_train.shape[0], 512, 512])\n",
        "            batch_y_placeholder.resize_([len(batch_inds), 1, x_train.shape[0], 512, 512])\n",
        "\n",
        "\n",
        "        batch_x_placeholder.copy_(torch.Tensor(x_train[batch_inds, np.newaxis, np.newaxis, :, :]))\n",
        "\n",
        "        batch_y_placeholder.copy_(torch.Tensor(y_train[batch_inds, np.newaxis, np.newaxis, :, :]))\n",
        "\n",
        "        \n",
        "        b_decision, b_loss = model(batch_x_placeholder, batch_y_placeholder)\n",
        "        b_decision = b_decision.detach().cpu().numpy()\n",
        "      \n",
        "        epoch_loss += float(b_loss) / iters_per_epoch  # CARE: WE SHOULD USE FLOAT OVER LOSS\n",
        "        true_positive += np.sum(y_train[batch_inds[0]].astype(int) == b_decision)\n",
        "        \n",
        "        b_loss.backward() # calculates derivations\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad() # CARE: MUST DO\n",
        "\n",
        "    epoch_train_accuracy = true_positive * 100.0 / len(x_train)\n",
        "    train_loss[e] = epoch_loss\n",
        "    train_acc[e] = epoch_train_accuracy\n",
        "    \n",
        " # Validating over validation data\n",
        "    with torch.no_grad():\n",
        "        model.eval()  # validation phase\n",
        "\n",
        "        val_inds = np.arange(len(x_val))\n",
        "\n",
        "        val_iters_per_epoch = int(np.ceil(1.0 * len(x_val) / batch_size))\n",
        "\n",
        "        epoch_validation_loss = 0\n",
        "        val_true_positive = 0\n",
        "\n",
        "\n",
        "        # iterating over the whole training set\n",
        "        for iter in range(val_iters_per_epoch):\n",
        "\n",
        "            val_batch_inds = val_inds[iter * batch_size: min(len(val_inds), (iter + 1) * batch_size)]\n",
        "\n",
        "            # reshaping placeholders\n",
        "            if len(batch_inds) != len(batch_x_placeholder):\n",
        "                batch_x_placeholder.resize_([len(batch_inds), 1, x_val.shape[0], 512, 512])\n",
        "                batch_y_placeholder.resize_([len(batch_inds), 1, x_val.shape[0], 512, 512])\n",
        "\n",
        "            batch_x_placeholder.copy_(torch.Tensor(x_train[batch_inds, np.newaxis, np.newaxis, :, :]))\n",
        "\n",
        "            batch_y_placeholder.copy_(torch.Tensor(y_train[batch_inds, np.newaxis, np.newaxis, :, :]))\n",
        "\n",
        "            b_decision, b_loss = model(batch_x_placeholder, batch_y_placeholder)\n",
        "            b_decision = b_decision.cpu().numpy()\n",
        "        \n",
        "            epoch_validation_loss += float(b_loss) / val_iters_per_epoch  # CARE: WE SHOULD USE FLOAT OVER LOSS\n",
        "            val_true_positive += np.sum(y_val[val_batch_inds].astype(int) == b_decision)\n",
        "                \n",
        "        epoch_validation_accuracy = val_true_positive * 100.0 / len(x_val)\n",
        "        val_loss[e] = epoch_validation_loss\n",
        "        val_acc[e] = epoch_validation_accuracy\n",
        "        # TO Complete\n",
        "    \n",
        "    print(f'Train epoch Loss: {epoch_loss:.4f}, Validation Loss: {epoch_validation_loss:.4f}')\n",
        "\n",
        "    # Saving the model and optimizer state\n",
        "    torch.save({\n",
        "            'epoch': e,\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'train_loss': epoch_loss,\n",
        "            'train_accuracy': epoch_train_accuracy,\n",
        "            # 'validation_loss': epoch_validation_loss,\n",
        "            # 'validation_accuracy': epoch_validation_accuracy\n",
        "        }, 'epoch_%d_state.pt' % e)\n",
        "    \n",
        "    \n",
        "\n",
        "    print('Epoch %d ended in %.2f secs.' % (e, time() - t_start,))\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:64: UserWarning: Using a target size (torch.Size([1, 8, 512, 512])) that is different to the input size (torch.Size([1, 1, 8, 512, 512])) is deprecated. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch Loss: 0.3843, Validation Loss: 0.5543\n",
            "Epoch 0 ended in 154.26 secs.\n",
            "Train epoch Loss: 0.3188, Validation Loss: 0.4864\n",
            "Epoch 1 ended in 154.25 secs.\n",
            "Train epoch Loss: 0.2830, Validation Loss: 0.4310\n",
            "Epoch 2 ended in 154.19 secs.\n",
            "Train epoch Loss: 0.2576, Validation Loss: 0.4125\n",
            "Epoch 3 ended in 154.17 secs.\n",
            "Train epoch Loss: 0.2373, Validation Loss: 0.3847\n",
            "Epoch 4 ended in 154.19 secs.\n",
            "Train epoch Loss: 0.2201, Validation Loss: 0.3487\n",
            "Epoch 5 ended in 154.22 secs.\n",
            "Train epoch Loss: 0.2048, Validation Loss: 0.3339\n",
            "Epoch 6 ended in 154.20 secs.\n",
            "Train epoch Loss: 0.1909, Validation Loss: 0.3181\n",
            "Epoch 7 ended in 154.17 secs.\n",
            "Train epoch Loss: 0.1782, Validation Loss: 0.3116\n",
            "Epoch 8 ended in 154.20 secs.\n",
            "Train epoch Loss: 0.1664, Validation Loss: 0.2990\n",
            "Epoch 9 ended in 154.20 secs.\n",
            "Train epoch Loss: 0.1556, Validation Loss: 0.2902\n",
            "Epoch 10 ended in 154.21 secs.\n",
            "Train epoch Loss: 0.1455, Validation Loss: 0.2842\n",
            "Epoch 11 ended in 154.17 secs.\n",
            "Train epoch Loss: 0.1362, Validation Loss: 0.2810\n",
            "Epoch 12 ended in 154.21 secs.\n",
            "Train epoch Loss: 0.1274, Validation Loss: 0.2701\n",
            "Epoch 13 ended in 154.23 secs.\n",
            "Train epoch Loss: 0.1193, Validation Loss: 0.2582\n",
            "Epoch 14 ended in 154.14 secs.\n",
            "Train epoch Loss: 0.1118, Validation Loss: 0.2496\n",
            "Epoch 15 ended in 154.13 secs.\n",
            "Train epoch Loss: 0.1049, Validation Loss: 0.2397\n",
            "Epoch 16 ended in 154.20 secs.\n",
            "Train epoch Loss: 0.0986, Validation Loss: 0.2354\n",
            "Epoch 17 ended in 154.19 secs.\n",
            "Train epoch Loss: 0.0928, Validation Loss: 0.2255\n",
            "Epoch 18 ended in 154.15 secs.\n",
            "Train epoch Loss: 0.0874, Validation Loss: 0.2174\n",
            "Epoch 19 ended in 154.22 secs.\n",
            "Train epoch Loss: 0.0825, Validation Loss: 0.2129\n",
            "Epoch 20 ended in 154.21 secs.\n",
            "Train epoch Loss: 0.0779, Validation Loss: 0.2094\n",
            "Epoch 21 ended in 154.15 secs.\n",
            "Train epoch Loss: 0.0736, Validation Loss: 0.2090\n",
            "Epoch 22 ended in 154.14 secs.\n",
            "Train epoch Loss: 0.0697, Validation Loss: 0.1981\n",
            "Epoch 23 ended in 154.18 secs.\n",
            "Train epoch Loss: 0.0661, Validation Loss: 0.2046\n",
            "Epoch 24 ended in 154.18 secs.\n",
            "Train epoch Loss: 0.0628, Validation Loss: 0.2025\n",
            "Epoch 25 ended in 154.24 secs.\n",
            "Train epoch Loss: 0.0597, Validation Loss: 0.2034\n",
            "Epoch 26 ended in 154.19 secs.\n",
            "Train epoch Loss: 0.0568, Validation Loss: 0.1913\n",
            "Epoch 27 ended in 154.17 secs.\n",
            "Train epoch Loss: 0.0540, Validation Loss: 0.1929\n",
            "Epoch 28 ended in 154.19 secs.\n",
            "Train epoch Loss: 0.0515, Validation Loss: 0.1950\n",
            "Epoch 29 ended in 154.22 secs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CsQbIoo78Xu",
        "outputId": "7a0aa116-5046-4c73-956c-3737993b5b70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "\n",
        "# loss\n",
        "ax = fig.add_subplot(121)\n",
        "ax.set_title('Loss')\n",
        "ax.set_xlabel('Loss')\n",
        "ax.set_ylabel('Epoch')\n",
        "ax.set_aspect('auto')\n",
        "\n",
        "plt.plot(train_loss, label='Train', color='blue', linewidth=3)\n",
        "plt.plot(val_loss, label='Validation', color='yellow', linewidth=3)\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f391a3f36d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFrnwNpp8Ulq"
      },
      "source": [
        "x_test = vessel12_23[216:224]\n",
        "y_test = vessel12_23_mask[216:224]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ntjDEAl8K5O",
        "outputId": "85e2f1fb-0a0f-4695-8373-978832505e79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "        model.eval()  # validation phase\n",
        "\n",
        "        val_inds = np.arange(len(x_test))\n",
        "\n",
        "        val_iters_per_epoch = int(np.ceil(1.0 * len(x_test) / batch_size))\n",
        "\n",
        "        epoch_validation_loss = 0\n",
        "        val_true_positive = 0\n",
        "        predictions = []\n",
        "\n",
        "        # iterating over the whole training set\n",
        "        for iter in range(val_iters_per_epoch):\n",
        "\n",
        "            val_batch_inds = val_inds[iter * batch_size: min(len(val_inds), (iter + 1) * batch_size)]\n",
        "\n",
        "            # reshaping placeholders\n",
        "            if len(batch_inds) != len(batch_x_placeholder):\n",
        "                batch_x_placeholder.resize_([len(batch_inds), 1, x_test.shape[0], 512, 512])\n",
        "                batch_y_placeholder.resize_([len(batch_inds), 1, x_test.shape[0], 512, 512])\n",
        "\n",
        "            batch_x_placeholder.copy_(torch.Tensor(x_test[batch_inds, np.newaxis, np.newaxis, :, :]))\n",
        "\n",
        "            batch_y_placeholder.copy_(torch.Tensor(y_test[batch_inds, np.newaxis, np.newaxis, :, :]))\n",
        "\n",
        "            b_decision, b_loss = model(batch_x_placeholder, batch_y_placeholder)\n",
        "            b_decision = b_decision.cpu().numpy()\n",
        "\n",
        "            predictions.append(b_decision)\n",
        "        \n",
        "            epoch_validation_loss += float(b_loss) / val_iters_per_epoch  # CARE: WE SHOULD USE FLOAT OVER LOSS\n",
        "            val_true_positive += np.sum(y_test[val_batch_inds].astype(int) == b_decision)\n",
        "                \n",
        "        epoch_validation_accuracy = val_true_positive * 100.0 / len(x_test)\n",
        "        val_loss = epoch_validation_loss\n",
        "        val_acc = epoch_validation_accuracy\n",
        "\n",
        "\n",
        "print('Test Loss %.4f' % val_loss)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:64: UserWarning: Using a target size (torch.Size([1, 8, 512, 512])) that is different to the input size (torch.Size([1, 1, 8, 512, 512])) is deprecated. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Loss 0.2675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNtBQY_h9Fc3"
      },
      "source": [
        "y_test = y_test.astype(int)\n",
        "predictions = np.concatenate(predictions)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AAPlIrY9Q6y",
        "outputId": "cb44ef0c-ec78-4043-9353-61650eb2e69b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 512, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtfZikTN9GWh",
        "outputId": "3e2d7812-9629-4f26-e335-810209b67c36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "right_images = x_test[predictions == y_test]\n",
        "print('there are %d correct predictions. We have chosen a few of them randomly.' % len(right_images))\n",
        "right_labels = predictions[predictions == y_test]\n",
        "right_indices = np.random.choice(np.arange(len(right_images)), size=80)\n",
        "\n",
        "images = right_images[right_indices]\n",
        "label_predictions = right_labels[right_indices]\n",
        "texts = [f'{label_predictions[i]}' for i in range(len(right_indices))]\n",
        "columns = 16\n",
        "rows = 5\n",
        "\n",
        "fig = plt.figure(figsize=(1.2 * columns, 1.2 * rows))\n",
        "\n",
        "for i in range(columns * rows):\n",
        "    ax = fig.add_subplot(rows, columns, i + 1)\n",
        "    ax.set_title(texts[i])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    plt.imshow(images[i].reshape((28, 28)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 0 correct predictions. We have chosen a few of them randomly.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1e72ab8ebf4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'there are %d correct predictions. We have chosen a few of them randomly.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mright_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mright_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mright_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mright_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 'a' cannot be empty unless no samples are taken"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8-CTJz4fNdj"
      },
      "source": [
        "torch.cuda.reset_max_memory_allocated"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5imb_Oi48pf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}