{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PLS.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sepehrilami/DataScienceInternship-AIMed/blob/master/PLS/PLS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt2LGmI0ePmv"
      },
      "source": [
        "#  Importing!\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pylab as plt\n",
        "from skimage.transform import resize\n",
        "from time import time\n",
        "\n",
        "# %matplotlib inline\n",
        "# from __future__ import print_function\n",
        "# from IPython.display import HTML\n",
        "# import torch.nn.parallel\n",
        "# import torch.backends.cudnn as cudnn\n",
        "# import nibabel as nib\n",
        "# import torch.utils.data\n",
        "# import torchvision.datasets as dset\n",
        "# import torchvision.transforms as transforms\n",
        "# import torchvision.utils as vutils"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ofren4nceaOB",
        "outputId": "d2ff9c18-24f9-4fee-da1f-61c65d21af40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Requird for reading mhd format\n",
        "!pip install SimpleITK\n",
        "import SimpleITK as sitk"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.6/dist-packages (2.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YVOxnbhedtA",
        "outputId": "ffc779c3-4789-409b-f8d6-b289ec6a9c30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Reading 3 samples from VESSEL12 dataset\n",
        "!wget https://www.dropbox.com/sh/1j2x17k8y18k3l6/AACkAc6bCEqYVXBdODFo6Iqya/VESSEL12_ExampleScans.tar.bz2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-01 12:37:11--  https://www.dropbox.com/sh/1j2x17k8y18k3l6/AACkAc6bCEqYVXBdODFo6Iqya/VESSEL12_ExampleScans.tar.bz2\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.1.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.1.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/raw/1j2x17k8y18k3l6/AACkAc6bCEqYVXBdODFo6Iqya/VESSEL12_ExampleScans.tar.bz2 [following]\n",
            "--2020-11-01 12:37:11--  https://www.dropbox.com/sh/raw/1j2x17k8y18k3l6/AACkAc6bCEqYVXBdODFo6Iqya/VESSEL12_ExampleScans.tar.bz2\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc4580a92237328b3488fe372c64.dl.dropboxusercontent.com/cd/0/inline/BCUiX8ODM16Lwy94uzrQhh0nGOdh3ADu5OhlCuxjB4bSn_P-cFlTSpbptsQCG4DUDAMcpenctbgO2wGGBw66PxhZJ7GJPYIqT5gifC7dFTSllg/file# [following]\n",
            "--2020-11-01 12:37:11--  https://uc4580a92237328b3488fe372c64.dl.dropboxusercontent.com/cd/0/inline/BCUiX8ODM16Lwy94uzrQhh0nGOdh3ADu5OhlCuxjB4bSn_P-cFlTSpbptsQCG4DUDAMcpenctbgO2wGGBw66PxhZJ7GJPYIqT5gifC7dFTSllg/file\n",
            "Resolving uc4580a92237328b3488fe372c64.dl.dropboxusercontent.com (uc4580a92237328b3488fe372c64.dl.dropboxusercontent.com)... 162.125.1.15, 2620:100:6016:15::a27d:10f\n",
            "Connecting to uc4580a92237328b3488fe372c64.dl.dropboxusercontent.com (uc4580a92237328b3488fe372c64.dl.dropboxusercontent.com)|162.125.1.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BCXBI-OYAwXXNtCbw4QRONAI3UzQtJ2gUKJ2S8xgKF9MrkgblJiRq_NMOZUN_tRyyVxxKkVqIjXMALBJTIFXfa4P5SIrfEwr5FmO172Ieu2Dq3-zWx-aEMyCkSNYgbX6CTVN-nLDxyGgshyjfLG37QidB6hicWAJeeL7MUTkgdrIogQZf5B2yc0jVsvAPu7k3WWCBbU8B0dzp0I417MXeRScrGtHUIgljbZnJbuIJADF9u5yJGg_b7J0uicHBQDv2h_6qsxk_U0cDd5pgcISb03VT9y5imtonNse-0LRpcvVOQj6Thnj-s1h02go1Gcisqh8tWakoxafl6glgQZR_jDZ/file [following]\n",
            "--2020-11-01 12:37:12--  https://uc4580a92237328b3488fe372c64.dl.dropboxusercontent.com/cd/0/inline2/BCXBI-OYAwXXNtCbw4QRONAI3UzQtJ2gUKJ2S8xgKF9MrkgblJiRq_NMOZUN_tRyyVxxKkVqIjXMALBJTIFXfa4P5SIrfEwr5FmO172Ieu2Dq3-zWx-aEMyCkSNYgbX6CTVN-nLDxyGgshyjfLG37QidB6hicWAJeeL7MUTkgdrIogQZf5B2yc0jVsvAPu7k3WWCBbU8B0dzp0I417MXeRScrGtHUIgljbZnJbuIJADF9u5yJGg_b7J0uicHBQDv2h_6qsxk_U0cDd5pgcISb03VT9y5imtonNse-0LRpcvVOQj6Thnj-s1h02go1Gcisqh8tWakoxafl6glgQZR_jDZ/file\n",
            "Reusing existing connection to uc4580a92237328b3488fe372c64.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 313639176 (299M) [application/octet-stream]\n",
            "Saving to: ‘VESSEL12_ExampleScans.tar.bz2’\n",
            "\n",
            "VESSEL12_ExampleSca 100%[===================>] 299.11M  49.9MB/s    in 6.1s    \n",
            "\n",
            "2020-11-01 12:37:18 (49.4 MB/s) - ‘VESSEL12_ExampleScans.tar.bz2’ saved [313639176/313639176]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQUlpJhPegK2"
      },
      "source": [
        "#Unzip samples\n",
        "!tar xf VESSEL12_ExampleScans.tar.bz2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpr1HAWnejIR"
      },
      "source": [
        "def read_mhd(file):\n",
        "    return sitk.GetArrayFromImage(sitk.ReadImage(file, sitk.sitkFloat32))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7S4vfmCpelWt",
        "outputId": "720c6ee1-69c6-40ad-ce66-81eca0b0e5d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vessel12_21 = read_mhd(\"Scans/VESSEL12_21.mhd\")\n",
        "vessel12_21.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(459, 512, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMbmW5D-enkM",
        "outputId": "bf88aa01-2710-4a62-890c-a7c608f70c83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vessel12_21_mask = read_mhd(\"Lungmasks/VESSEL12_21.mhd\")\n",
        "vessel12_21_mask.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(459, 512, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6wZrxsdep0W"
      },
      "source": [
        "def draw(images, columns=4):\n",
        "    rows = int(np.ceil(images.shape[0] / columns))\n",
        "    max_size = 20\n",
        "    \n",
        "    width = max(columns * 5, max_size)\n",
        "    height = width * rows // columns\n",
        "\n",
        "    plt.figure(figsize=(width, height))\n",
        "    plt.gray()\n",
        "    plt.subplots_adjust(0,0,1,1,0.01,0.01)\n",
        "    for i in range(images.shape[0]):\n",
        "        plt.subplot(rows,columns,i+1), plt.imshow(images[i]), plt.axis('off')\n",
        "        # use plt.savefig(...) here if you want to save the images as .jpg, e.g.,\n",
        "    plt.show()\n",
        "\n",
        "def draw_masked(images, masks, columns=4):\n",
        "    assert images.shape == masks.shape\n",
        "    \n",
        "    rows = int(np.ceil(images.shape[0] / columns))\n",
        "    max_size = 20\n",
        "    \n",
        "    width = min(columns * 5, max_size)\n",
        "    height = width * rows // columns\n",
        "\n",
        "    fig = plt.figure(figsize=(width, height))\n",
        "    plt.gray()\n",
        "    plt.subplots_adjust(0,0,1,1,0.01,0.01)\n",
        "    \n",
        "    X, Y = np.meshgrid(np.arange(masks.shape[1]), np.arange(masks.shape[2]))\n",
        "    \n",
        "    for i in range(images.shape[0]):\n",
        "        ax = fig.add_subplot(rows,columns,i+1)\n",
        "        if masks[i].sum() > 0:\n",
        "            ax.contour(X, Y, masks[i], 1, colors='red', linewidths=0.5)\n",
        "        ax.imshow(images[i], origin='lower', cmap='gray')\n",
        "        plt.axis('off')\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sq2yT5YHer8p"
      },
      "source": [
        "# custom weights initialization\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.01)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.01)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITK5VjD7ev4t"
      },
      "source": [
        "class DSconv(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, DSkernel, depth_stride, DSstride, DSpadding, dilation=1):\n",
        "    super(DSconv, self).__init__()\n",
        "\n",
        "    self.dsconv = nn.Sequential(\n",
        "        #Input is 10, 512, 512\n",
        "\n",
        "        nn.Conv3d(in_channels, in_channels, DSkernel, depth_stride, DSpadding, dilation, groups = in_channels),\n",
        "\n",
        "        nn.BatchNorm3d(in_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv3d(in_channels, out_channels, 1 ,DSstride, 0, dilation),\n",
        "        nn.BatchNorm3d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    # print(\"dsconv shape of input:\", input.shape)  \n",
        "    return self.dsconv(input)\n",
        "\n",
        "\n",
        "class DRDB(nn.Module):\n",
        "      def __init__(self, in_channels, DRDBpadding):\n",
        "        super(DRDB, self).__init__()\n",
        "        \n",
        "        DSkernel = 3\n",
        "        DSstride = 1\n",
        "        DSpadding = DRDBpadding\n",
        "        self.conv_1 = DSconv(in_channels, in_channels, 3, 1, DSstride, 1, 1)\n",
        "        self.conv_2 = DSconv(in_channels * 2 , in_channels * 2, 3, 1, DSstride, 2, 2)\n",
        "        self.conv_3 = DSconv(in_channels * 4, in_channels * 4, 3, 1, DSstride, 3, 3)\n",
        "        self.conv_4 = DSconv(in_channels * 8, in_channels * 8, 3, 1, DSstride, 4, 4)\n",
        "        \n",
        "        self.final_conv = nn.Conv3d(in_channels * 16, in_channels, 1, DSstride, 0,bias=False)\n",
        "\n",
        "      def forward(self, DRDBinput):\n",
        "        first_convolved = self.conv_1(DRDBinput)\n",
        "        # print(first_convolved.shape)\n",
        "        concat = torch.cat([first_convolved, DRDBinput], dim=1)\n",
        "        second_convolved = self.conv_2(concat)\n",
        "        # print(\"Testing\")\n",
        "        # print(second_convolved.shape)\n",
        "        # print(DRDBinput.shape)\n",
        "        concat = torch.cat([second_convolved, concat], dim=1)\n",
        "        third_convolved = self.conv_3(concat)\n",
        "        concat = torch.cat([third_convolved, concat], dim=1)\n",
        "        forth_convolved = self.conv_4(concat)\n",
        "        concat = torch.cat([forth_convolved, concat], dim=1)\n",
        "        xg0 = self.final_conv(concat)\n",
        "        # fff = xg0 + DRDBinput\n",
        "        # print(fff.shape)\n",
        "        return xg0 + DRDBinput"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytXb2mA3ewps"
      },
      "source": [
        "#Testing DRDB\n",
        "\n",
        "# test = torch.zeros(size= [1, 17, 10, 512, 512], device = 'cuda:0', dtype = torch.float16)\n",
        "# drdb = DRDB(17, 0)\n",
        "# drdb = drdb.to('cuda:0').half()\n",
        "# out = drdb(test)\n",
        "# out.shape"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lImBSDoe350"
      },
      "source": [
        "#Testing DSconv\n",
        "\n",
        "# test = torch.zeros(size= [1, 1, 8, 512, 512], device = 'cuda:0', dtype = torch.float16)\n",
        "# dsconv = nn.Sequential( DSconv(1, 16, 3, 2, 1, 1, dilation = 1),\n",
        "# DSconv(16, 16, 3, 2, 1, 1, dilation = 1),\n",
        "# DSconv(16, 1, 3, 2, 1, 1, dilation = 1))\n",
        "# dsconv = dsconv.to('cuda:0').half()\n",
        "# out = dsconv(test)\n",
        "# out.shape"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsLOEu-me1u1",
        "outputId": "78af7565-8a4c-46e2-9698-09d8c4c490df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.cuda.empty_cache()\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH9A1blAe6eS"
      },
      "source": [
        "class PLSnet(nn.Module):\n",
        "  def __init__(self, DSkernel, DSstride, DSpadding, C):\n",
        "    super(PLSnet, self).__init__()\n",
        "\n",
        "    self.dsconvolve_1 = DSconv(1, 16, DSkernel, 2, DSstride, DSpadding)\n",
        "    self.dsconvolve_2 = DSconv(17, 64, DSkernel, 2, DSstride, DSpadding)\n",
        "    self.dsconvolve_3 = DSconv(65, 128, DSkernel, 2, DSstride, DSpadding)\n",
        "\n",
        "    self.mid_dsconvolve_1 = DSconv(17, 2*C, DSkernel, 1, DSstride, DSpadding, 1)\n",
        "    self.mid_dsconvolve_2 = DSconv(65, 2*C, DSkernel, 1, DSstride, DSpadding, 1)\n",
        "    \n",
        "    self.decoder_dsconvolve_1 = DSconv(129, 2*C, DSkernel, 1, DSstride, DSpadding, 1)\n",
        "    self.decoder_dsconvolve_2 = DSconv(4*C, 2*C, DSkernel, 1, DSstride, DSpadding, 1)\n",
        "    self.decoder_dsconvolve_3 = DSconv(4*C, 2*C, DSkernel, 1, DSstride, DSpadding, 1)\n",
        "\n",
        "    self.oneconv = nn.Conv3d(2*C, 1, 1, DSstride, 0)\n",
        "\n",
        "    DRDBpadding = DSpadding\n",
        "    self.drdb = DRDB(17, DRDBpadding)\n",
        "    self.drdbx2 = DRDB(65, DRDBpadding)\n",
        "    self.drdbx4 = DRDB(129, DRDBpadding)\n",
        "\n",
        "    self.TLupsample = nn.Upsample(scale_factor = 2, mode='trilinear')\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, InputImage, real_mask):\n",
        "\n",
        "    # resolution = 1 in encoder\n",
        "    DSconv_output = self.dsconvolve_1(InputImage)\n",
        "    # print(\"dsconv: \", DSconv_1.shape)\n",
        "    InputImage = nn.functional.interpolate(InputImage, scale_factor = 0.5, mode='trilinear')\n",
        "    # print(\"image: \", InputImage.shape)\n",
        "    concat_output = torch.cat([DSconv_output,InputImage], dim=1)\n",
        "    DRDB1_output = self.drdb(concat_output)\n",
        "    # resolution = 2 in encoder\n",
        "    DSconv_output = self.dsconvolve_2(DRDB1_output)\n",
        "    InputImage = nn.functional.interpolate(InputImage, scale_factor = 0.5, mode='trilinear')\n",
        "    concat_output = torch.cat([DSconv_output,InputImage], dim = 1)\n",
        "    DRDB2_output = self.drdbx2(self.drdbx2(concat_output))\n",
        "    # resolution = 3 in encoder\n",
        "    DSconv_output = self.dsconvolve_3(DRDB2_output)\n",
        "\n",
        "    InputImage = nn.functional.interpolate(InputImage, scale_factor = 0.5, mode = 'trilinear')\n",
        "    concat_output = torch.cat([DSconv_output,InputImage], dim = 1)\n",
        "\n",
        "    DSconv_output = self.decoder_dsconvolve_1(self.drdbx4(self.drdbx4(self.drdbx4(self.drdbx4(concat_output)))))\n",
        "    upsample_output = self.TLupsample(DSconv_output) \n",
        "    # resolution = 2 in decoder\n",
        "    DSconv_output = self.mid_dsconvolve_2(DRDB2_output)\n",
        "    concat_output = torch.cat([upsample_output, DSconv_output], dim = 1)\n",
        "    DSconv_output = self.decoder_dsconvolve_2(concat_output)\n",
        "    upsample_output = self.TLupsample(DSconv_output)\n",
        "    # resolution = 1 in decoder\n",
        "    DSconv_output = self.mid_dsconvolve_1(DRDB1_output)\n",
        "    concat_output = torch.cat([upsample_output, DSconv_output], dim = 1)\n",
        "    DSconv_output = self.decoder_dsconvolve_2(concat_output)\n",
        "    upsample_output = self.TLupsample(DSconv_output)\n",
        "    # resolution = 0 in decoder\n",
        "\n",
        "    output = self.oneconv(upsample_output)\n",
        "\n",
        "    predicted = self.sigmoid(output)\n",
        "\n",
        "    # print(predicted.shape)\n",
        "    # print(real_mask.squeeze(dim = 1).shape)\n",
        "    # print(\"LOSS:\")\n",
        "\n",
        "    loss_output = F.binary_cross_entropy(predicted, real_mask.squeeze(dim = 1))\n",
        "    # print(loss_output)\n",
        "    \n",
        "\n",
        "    return predicted, loss_output"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXZmo1NHfBHh"
      },
      "source": [
        "# in_channels = 10\n",
        "# out_channels = 256\n",
        "DSkernel = 3\n",
        "DSstride = 1\n",
        "DSpadding = 1\n",
        "\n",
        "C = 6   #number of classes\n",
        "\n",
        "model = PLSnet(DSkernel, DSstride, DSpadding, C)\n",
        "model = model.cuda()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GL82GBPfD8r"
      },
      "source": [
        "optimizer = torch.optim.Adam(filter(\n",
        "    lambda p : p.requires_grad, model.parameters()),\n",
        "    lr = 0.001\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0x7HUnE5fZa"
      },
      "source": [
        "# output = torch.randn(1, 2, 8, 512, 512, dtype=torch.float32)\n",
        "# print(output.shape)\n",
        "# target = torch.empty(1, 8, 512, 512, dtype=torch.float32).random_(2)\n",
        "# print(target.shape)\n",
        "# print(F.cross_entropy(output, target))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHXu6wm5fHv3"
      },
      "source": [
        "batch_size = 1\n",
        "batch_x_placeholder = torch.zeros(size= [batch_size, 1, 8, 512, 512], dtype = torch.float32, device = 'cuda:0')\n",
        "batch_y_placeholder = torch.zeros(size= [batch_size, 1, 8, 512, 512], dtype = torch.float32, device = 'cuda:0')\n",
        "\n",
        "x_train = vessel12_21[200:208]\n",
        "y_train = vessel12_21_mask[200:208]\n",
        "x_val = vessel12_21[208:216]\n",
        "y_val = vessel12_21_mask[208:216]\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "train_loss = np.zeros((batch_size * epochs,))\n",
        "val_loss = np.zeros((batch_size * epochs,))\n",
        "train_acc = np.zeros((batch_size * epochs,))\n",
        "val_acc = np.zeros((batch_size * epochs,))\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEDxVzxDfK7F",
        "outputId": "12dd3c2f-600c-4369-ecc6-c7b21f72e022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "iters_per_epoch = int(np.ceil(1.0 * len(x_train) / batch_size))\n",
        "\n",
        "for e in range(epochs):\n",
        "    t_start = time()\n",
        "\n",
        "    model.train() # training phase\n",
        "\n",
        "    # shuffling\n",
        "    inds = np.arange(len(x_train))\n",
        "    np.random.shuffle(inds)\n",
        "\n",
        "    epoch_loss = 0\n",
        "    true_positive = 0\n",
        "\n",
        "\n",
        "    # iterating over the whole training set\n",
        "    for iter in range(iters_per_epoch):\n",
        "\n",
        "        batch_inds = inds[iter * batch_size: min(len(inds), (iter + 1) * batch_size)]\n",
        "        # print(batch_inds)\n",
        "\n",
        "        # reshaping placeholders\n",
        "        if len(batch_inds) != len(batch_x_placeholder):\n",
        "            batch_x_placeholder.resize_([len(batch_inds), 1, 8, 512, 512])\n",
        "            batch_y_placeholder.resize_([len(batch_inds), 1, 8, 512, 512])\n",
        "\n",
        "\n",
        "        batch_x_placeholder.copy_(torch.Tensor(x_train[batch_inds, np.newaxis, np.newaxis, :, :]))\n",
        "\n",
        "        batch_y_placeholder.copy_(torch.Tensor(y_train[batch_inds, np.newaxis, np.newaxis, :, :]))\n",
        "\n",
        "        \n",
        "        b_decision, b_loss = model(batch_x_placeholder, batch_y_placeholder)\n",
        "        b_decision = b_decision.detach().cpu().numpy()\n",
        "      \n",
        "        epoch_loss += float(b_loss) / iters_per_epoch  # CARE: WE SHOULD USE FLOAT OVER LOSS\n",
        "        true_positive += np.sum(y_train[batch_inds[0]].astype(int) == b_decision)\n",
        "        \n",
        "        b_loss.backward() # calculates derivations\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad() # CARE: MUST DO\n",
        "\n",
        "    epoch_train_accuracy = true_positive * 100.0 / len(x_train)\n",
        "    train_loss[e] = epoch_loss\n",
        "    train_acc[e] = epoch_train_accuracy\n",
        "    \n",
        " # Validating over validation data\n",
        "    with torch.no_grad():\n",
        "        model.eval()  # validation phase\n",
        "\n",
        "        val_inds = np.arange(len(x_val))\n",
        "\n",
        "        val_iters_per_epoch = int(np.ceil(1.0 * len(x_val) / batch_size))\n",
        "\n",
        "        epoch_validation_loss = 0\n",
        "        val_true_positive = 0\n",
        "\n",
        "\n",
        "        # iterating over the whole training set\n",
        "        for iter in range(val_iters_per_epoch):\n",
        "\n",
        "            val_batch_inds = val_inds[iter * batch_size: min(len(val_inds), (iter + 1) * batch_size)]\n",
        "\n",
        "            # reshaping placeholders\n",
        "            if len(batch_inds) != len(batch_x_placeholder):\n",
        "                batch_x_placeholder.resize_([len(batch_inds), 1, 8, 512, 512])\n",
        "                batch_y_placeholder.resize_([len(batch_inds), 1, 8, 512, 512])\n",
        "\n",
        "            batch_x_placeholder.copy_(torch.Tensor(x_train[batch_inds, np.newaxis, np.newaxis, :, :]))\n",
        "\n",
        "            batch_y_placeholder.copy_(torch.Tensor(y_train[batch_inds, np.newaxis, np.newaxis, :, :]))\n",
        "\n",
        "            b_decision, b_loss = model(batch_x_placeholder, batch_y_placeholder)\n",
        "            b_decision = b_decision.cpu().numpy()\n",
        "        \n",
        "            epoch_validation_loss += float(b_loss) / val_iters_per_epoch  # CARE: WE SHOULD USE FLOAT OVER LOSS\n",
        "            val_true_positive += np.sum(y_val[val_batch_inds].astype(int) == b_decision)\n",
        "                \n",
        "        epoch_validation_accuracy = val_true_positive * 100.0 / len(x_val)\n",
        "        val_loss[e] = epoch_validation_loss\n",
        "        val_acc[e] = epoch_validation_accuracy\n",
        "        # TO Complete\n",
        "    \n",
        "    print(f'Train epoch Loss: {epoch_loss:.4f}, Validation Loss: {epoch_validation_loss:.4f}')\n",
        "\n",
        "    # Saving the model and optimizer state\n",
        "    torch.save({\n",
        "            'epoch': e,\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'train_loss': epoch_loss,\n",
        "            'train_accuracy': epoch_train_accuracy,\n",
        "            # 'validation_loss': epoch_validation_loss,\n",
        "            # 'validation_accuracy': epoch_validation_accuracy\n",
        "        }, 'epoch_%d_state.pt' % e)\n",
        "    \n",
        "    \n",
        "\n",
        "    print('Epoch %d ended in %.2f secs.' % (e, time() - t_start,))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: Using a target size (torch.Size([1, 8, 512, 512])) that is different to the input size (torch.Size([1, 1, 8, 512, 512])) is deprecated. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train epoch Loss: 0.1407, Validation Loss: 0.2627\n",
            "Epoch 0 ended in 19.77 secs.\n",
            "Train epoch Loss: 0.1319, Validation Loss: 0.2538\n",
            "Epoch 1 ended in 19.99 secs.\n",
            "Train epoch Loss: 0.1239, Validation Loss: 0.2571\n",
            "Epoch 2 ended in 19.62 secs.\n",
            "Train epoch Loss: 0.1165, Validation Loss: 0.2464\n",
            "Epoch 3 ended in 19.49 secs.\n",
            "Train epoch Loss: 0.1096, Validation Loss: 0.2367\n",
            "Epoch 4 ended in 19.65 secs.\n",
            "Train epoch Loss: 0.1033, Validation Loss: 0.2356\n",
            "Epoch 5 ended in 19.74 secs.\n",
            "Train epoch Loss: 0.0975, Validation Loss: 0.2260\n",
            "Epoch 6 ended in 19.62 secs.\n",
            "Train epoch Loss: 0.0920, Validation Loss: 0.2204\n",
            "Epoch 7 ended in 19.58 secs.\n",
            "Train epoch Loss: 0.0870, Validation Loss: 0.2206\n",
            "Epoch 8 ended in 19.63 secs.\n",
            "Train epoch Loss: 0.0824, Validation Loss: 0.2178\n",
            "Epoch 9 ended in 19.69 secs.\n",
            "Train epoch Loss: 0.0780, Validation Loss: 0.2127\n",
            "Epoch 10 ended in 19.63 secs.\n",
            "Train epoch Loss: 0.0740, Validation Loss: 0.2031\n",
            "Epoch 11 ended in 19.64 secs.\n",
            "Train epoch Loss: 0.0702, Validation Loss: 0.2014\n",
            "Epoch 12 ended in 19.59 secs.\n",
            "Train epoch Loss: 0.0667, Validation Loss: 0.1964\n",
            "Epoch 13 ended in 19.61 secs.\n",
            "Train epoch Loss: 0.0635, Validation Loss: 0.1900\n",
            "Epoch 14 ended in 19.67 secs.\n",
            "Train epoch Loss: 0.0605, Validation Loss: 0.1962\n",
            "Epoch 15 ended in 19.67 secs.\n",
            "Train epoch Loss: 0.0577, Validation Loss: 0.1840\n",
            "Epoch 16 ended in 19.68 secs.\n",
            "Train epoch Loss: 0.0551, Validation Loss: 0.1706\n",
            "Epoch 17 ended in 19.64 secs.\n",
            "Train epoch Loss: 0.0526, Validation Loss: 0.1744\n",
            "Epoch 18 ended in 19.71 secs.\n",
            "Train epoch Loss: 0.0503, Validation Loss: 0.1810\n",
            "Epoch 19 ended in 19.62 secs.\n",
            "Train epoch Loss: 0.0481, Validation Loss: 0.1694\n",
            "Epoch 20 ended in 19.68 secs.\n",
            "Train epoch Loss: 0.0460, Validation Loss: 0.1662\n",
            "Epoch 21 ended in 19.65 secs.\n",
            "Train epoch Loss: 0.0440, Validation Loss: 0.1701\n",
            "Epoch 22 ended in 19.59 secs.\n",
            "Train epoch Loss: 0.0422, Validation Loss: 0.1680\n",
            "Epoch 23 ended in 19.62 secs.\n",
            "Train epoch Loss: 0.0405, Validation Loss: 0.1614\n",
            "Epoch 24 ended in 19.66 secs.\n",
            "Train epoch Loss: 0.0389, Validation Loss: 0.1641\n",
            "Epoch 25 ended in 19.58 secs.\n",
            "Train epoch Loss: 0.0374, Validation Loss: 0.1600\n",
            "Epoch 26 ended in 19.62 secs.\n",
            "Train epoch Loss: 0.0359, Validation Loss: 0.1562\n",
            "Epoch 27 ended in 19.63 secs.\n",
            "Train epoch Loss: 0.0346, Validation Loss: 0.1555\n",
            "Epoch 28 ended in 19.62 secs.\n",
            "Train epoch Loss: 0.0333, Validation Loss: 0.1466\n",
            "Epoch 29 ended in 19.67 secs.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CsQbIoo78Xu",
        "outputId": "c7b76e7e-1edc-4f6d-fa3d-9cc36022790c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = plt.figure(figsize=(16, 8))\n",
        "\n",
        "\n",
        "# loss\n",
        "ax = fig.add_subplot(121)\n",
        "ax.set_title('Loss')\n",
        "ax.set_xlabel('Loss')\n",
        "ax.set_ylabel('Epoch')\n",
        "ax.set_aspect('auto')\n",
        "\n",
        "plt.plot(train_loss, label='Train', color='blue', linewidth=3)\n",
        "plt.plot(val_loss, label='Validation', color='yellow', linewidth=3)\n",
        "\n",
        "plt.legend()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3b3aee95c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFrnwNpp8Ulq"
      },
      "source": [
        "x_test = vessel12_21[216:224]\n",
        "y_test = vessel12_21_mask[216:224]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ntjDEAl8K5O",
        "outputId": "266c8a0b-6ee7-499c-e8ad-259ab00823d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "with torch.no_grad():\n",
        "        model.eval()  # validation phase\n",
        "\n",
        "        val_inds = np.arange(len(x_test))\n",
        "\n",
        "        val_iters_per_epoch = int(np.ceil(1.0 * len(x_test) / batch_size))\n",
        "\n",
        "        epoch_validation_loss = 0\n",
        "        val_true_positive = 0\n",
        "        predictions = []\n",
        "\n",
        "        # iterating over the whole training set\n",
        "        for iter in range(val_iters_per_epoch):\n",
        "\n",
        "            val_batch_inds = val_inds[iter * batch_size: min(len(val_inds), (iter + 1) * batch_size)]\n",
        "\n",
        "            # reshaping placeholders\n",
        "            if len(batch_inds) != len(batch_x_placeholder):\n",
        "                batch_x_placeholder.resize_([len(batch_inds), 1, 8, 512, 512])\n",
        "                batch_y_placeholder.resize_([len(batch_inds), 1, 8, 512, 512])\n",
        "\n",
        "            batch_x_placeholder.copy_(torch.Tensor(x_test[batch_inds, np.newaxis, np.newaxis, :, :]))\n",
        "\n",
        "            batch_y_placeholder.copy_(torch.Tensor(y_test[batch_inds, np.newaxis, np.newaxis, :, :]))\n",
        "\n",
        "            b_decision, b_loss = model(batch_x_placeholder, batch_y_placeholder)\n",
        "            b_decision = b_decision.cpu().numpy()\n",
        "\n",
        "            predictions.append(b_decision)\n",
        "        \n",
        "            epoch_validation_loss += float(b_loss) / val_iters_per_epoch  # CARE: WE SHOULD USE FLOAT OVER LOSS\n",
        "            val_true_positive += np.sum(y_test[val_batch_inds].astype(int) == b_decision)\n",
        "                \n",
        "        epoch_validation_accuracy = val_true_positive * 100.0 / len(x_test)\n",
        "        val_loss = epoch_validation_loss\n",
        "        val_acc = epoch_validation_accuracy\n",
        "\n",
        "\n",
        "print('Test Loss %.4f' % val_loss)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3121: UserWarning: Default upsampling behavior when mode=trilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:3000: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and uses scale_factor directly, instead of relying on the computed output size. If you wish to keep the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
            "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:68: UserWarning: Using a target size (torch.Size([1, 8, 512, 512])) that is different to the input size (torch.Size([1, 1, 8, 512, 512])) is deprecated. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Loss 0.2480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNtBQY_h9Fc3"
      },
      "source": [
        "y_test = y_test.astype(int)\n",
        "predictions = np.concatenate(predictions)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AAPlIrY9Q6y",
        "outputId": "08941b1b-977c-49be-f36c-2ea9bf526b02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 512, 512)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtfZikTN9GWh",
        "outputId": "77caf07e-ea24-4749-94bf-976412492295",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "right_images = x_test[predictions == y_test]\n",
        "print('there are %d correct predictions. We have chosen a few of them randomly.' % len(right_images))\n",
        "right_labels = predictions[predictions == y_test]\n",
        "right_indices = np.random.choice(np.arange(len(right_images)), size=80)\n",
        "\n",
        "images = right_images[right_indices]\n",
        "label_predictions = right_labels[right_indices]\n",
        "texts = [f'{label_predictions[i]}' for i in range(len(right_indices))]\n",
        "columns = 16\n",
        "rows = 5\n",
        "\n",
        "fig = plt.figure(figsize=(1.2 * columns, 1.2 * rows))\n",
        "\n",
        "for i in range(columns * rows):\n",
        "    ax = fig.add_subplot(rows, columns, i + 1)\n",
        "    ax.set_title(texts[i])\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    plt.imshow(images[i].reshape((28, 28)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-1e72ab8ebf4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mright_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'there are %d correct predictions. We have chosen a few of them randomly.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mright_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mright_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8-CTJz4fNdj",
        "outputId": "f486c11b-3309-401c-a29f-f8284b9a532d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "torch.cuda.reset_max_memory_allocated"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function torch.cuda.memory.reset_max_memory_allocated>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjyfHpXG_PvE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}