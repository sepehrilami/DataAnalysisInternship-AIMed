{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PLS-NET.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sepehrilami/DataScienceInternship-AIMed/blob/master/PLS/PLS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTIoGL5FIMLS"
      },
      "source": [
        "#  Importing!\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from __future__ import print_function\n",
        "#%matplotlib inline\n",
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89beIO7o--5a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a5KnhcuQ7E7"
      },
      "source": [
        "# custom weights initialization\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.01)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.01)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajrvW218dM3i"
      },
      "source": [
        "Defining Depthwise Separable (DS) Convolution And Dilated Residual Dense Block (DRDB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq545Tn1RGw9"
      },
      "source": [
        "class DSconv(nn.Module):\n",
        "  def __init__(in_channels, out_channels, DSkernel, DSstride, DSpadding, dilation = True):\n",
        "    super(DSconv, self).__init__()\n",
        "\n",
        "    self.dsconv = nn.Sequential(\n",
        "\n",
        "        #nn.Conv3d(in_chans, in_chans * k, kernel_size, groups = in_chans)\n",
        "        #here k is M * N or just M or 1 ??\n",
        "        nn.Conv3d(in_channels, in_channels, DSkernel, DSstride, DSpadding, dilation, groups = in_channels),\n",
        "\n",
        "        nn.BatchNorm3d(in_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv3d(in_channels, out_channels, 1 ,DSstride, DSpadding),\n",
        "        nn.BatchNorm3d(out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.dsconv(input)\n",
        "\n",
        "\n",
        "class DRDB(nn.Module):\n",
        "      def __init__(self, in_channels, out_channels, DSkernel, DSstride, DSpadding):\n",
        "        super(DRDB, self).__init__()\n",
        "        \n",
        "        #second parameter: in_channels or out_channels??\n",
        "        self.conv_1 = DSconv(in_channels, in_channels, DSkernel, DSstride, DSpadding, dilation = 1)\n",
        "        self.conv_2 = DSconv(in_channels, in_channels, DSkernel, DSstride, DSpadding, dilation = 2)\n",
        "        self.conv_3 = DSconv(in_channels, in_channels, DSkernel, DSstride, DSpadding, dilation = 3)\n",
        "        self.conv_4 = DSconv(in_channels, in_channels, DSkernel, DSstride, DSpadding, dilation = 4)\n",
        "        #what does g0 mean?\n",
        "        self.g0 = DSconv(in_channels, in_channels, 1, DSstride, DSpadding, dilation = 4)\n",
        "\n",
        "      def forward(self, x):\n",
        "        x1 = self.conv_1(x)\n",
        "        concat_1 = torch.cat([x1,x], dim=1) # concatting the input and output of the same convolution\n",
        "        x2 = self.conv_2(concat_1)\n",
        "        concat_2 = torch.cat([x2,x11], dim=1)\n",
        "        x3 = self.conv_3(concat_2)\n",
        "        concat_3 = torch.cat([x3,x22], dim=1)\n",
        "        x4 = self.conv_4(concat_3)\n",
        "        concat_4 = torch.cat([x4,x33], dim=1)\n",
        "        xg0 = self.g0(concat_4)\n",
        "        \n",
        "        return xg0 + x\n",
        "\n",
        "        #Please write a full commit about your variable names\n",
        "        # I've renamed some of them, others are left\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUdT9ylmOXTs"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2XZejqbOV-V"
      },
      "source": [
        "class PLSnet(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, DSkernel, DSstride, DSpadding):\n",
        "    super(PLSnet, self).__init__()\n",
        "\n",
        "    self.TLupsample = nn.Upsample(scale_factor=2, mode='trilinear')\n",
        "    self.TLdownsample = nn.functional.interpolate(scale_factor= 1/2, mode='trilinear')\n",
        "    self.oneconv = nn.Conv3d(in_channels, out_channels, 1 ,DSstride, DSpadding)\n",
        "    self.softmaxAF = nn.Softmax()\n",
        "\n",
        "  def forward(self, InputImage):\n",
        "    # resolution = 1 in encoder\n",
        "    g1 = DSconv(InputImage)\n",
        "    InputImage = self.TLdownsample(InputImage)\n",
        "    g1 = torch.cat([g1,InputImage], dim=1)\n",
        "    g1 = DRDB(g1)\n",
        "    # resolution = 2 in encoder\n",
        "    g2 = DSconv(g1)\n",
        "    InputImage = self.TLdownsample(InputImage)\n",
        "    g2 = torch.cat([g2,InputImage], dim=1)\n",
        "    g2 = DRDB(g2)\n",
        "    g2 = DRDB(g2) # Don't know, but the paper's architecture has a DRDBx2! and I don't know what's that mean!\n",
        "    # resolution = 3 in encoder\n",
        "    g3 = DSconv(g2)\n",
        "\n",
        "    InputImage = self.TLdownsample(InputImage)\n",
        "    g3 = torch.cat([g3,InputImage], dim=1)\n",
        "    g3 = DRDB(g3)\n",
        "    g3 = DRDB(g3)\n",
        "    g3 = DRDB(g3)\n",
        "    g3 = DRDB(g3)\n",
        "    g3 = DSconv(g3)\n",
        "    g3d = self.TLupsample(g3) # g3 that got upsample and is placed in decoder\n",
        "    # resolution = 2 in decoder\n",
        "    g2d = torch.cat([g3d,g2], dim=1)\n",
        "    g2d = DSconv(g2d)\n",
        "    g2d = self.TLupsample(g2d)\n",
        "    # resolution = 1 in decoder\n",
        "    g1d = torch.cat([g2d,g1], dim=1)\n",
        "    g1d = DSconv(g1d)\n",
        "    g1d = self.TLupsample(g1d)\n",
        "    # resolution = 0 in decoder\n",
        "    g0d = self.oneconv(g1d)\n",
        "    return self.Softmax(g0d) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d70IKAnMdrCe"
      },
      "source": [
        "optimizer = torch.optim.Adam(filter(\n",
        "    lambda p : p.requires_grad, model.parameters()),\n",
        "    lr = 0.001\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGKobSbwi-Bu"
      },
      "source": [
        "model = PLSnet()\n",
        "model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ0tPWMejHN2"
      },
      "source": [
        "from time import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BphBFBIri5E0"
      },
      "source": [
        "iters_per_epoch = int(np.ceil(1.0 * len(x_train) / batch_size))\n",
        "\n",
        "for e in range(epochs):\n",
        "    t_start = time()\n",
        "\n",
        "    model.train() # training phase\n",
        "\n",
        "    # shuffling\n",
        "    inds = np.arange(len(x_train))\n",
        "    np.random.shuffle(inds)\n",
        "\n",
        "    epoch_loss = 0\n",
        "    true_positive = 0\n",
        "\n",
        "\n",
        "    # iterating over the whole training set\n",
        "    for iter in range(iters_per_epoch):\n",
        "\n",
        "        batch_inds = inds[iter * batch_size: min(len(inds), (iter + 1) * batch_size)]\n",
        "\n",
        "        # reshaping placeholders\n",
        "        if len(batch_inds) != len(batch_x_placeholder):\n",
        "            batch_x_placeholder.resize_([len(batch_inds), 1, 28, 28])\n",
        "            batch_y_placeholder.resize_([len(batch_inds)])\n",
        "\n",
        "        batch_x_placeholder.copy_(torch.Tensor(x_train[batch_inds, np.newaxis, :, :]))\n",
        "        batch_y_placeholder.copy_(torch.Tensor(y_train[batch_inds].astype(int)))\n",
        "\n",
        "        b_decision, b_loss = model(batch_x_placeholder, batch_y_placeholder)\n",
        "        b_decision = b_decision.cpu().numpy()\n",
        "      \n",
        "        epoch_loss += float(b_loss) / iters_per_epoch  # CARE: WE SHOULD USE FLOAT OVER LOSS\n",
        "        true_positive += np.sum(y_train[batch_inds].astype(int) == b_decision)\n",
        "\n",
        "        b_loss.backward() # calculates derivations\n",
        "\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad() # CARE: MUST DO\n",
        "\n",
        "    epoch_train_accuracy = true_positive * 100.0 / len(x_train)\n",
        "    train_loss[e] = epoch_loss\n",
        "    train_acc[e] = epoch_train_accuracy\n",
        "    \n",
        " # Validating over validation data\n",
        "    with torch.no_grad():\n",
        "        model.eval()  # validation phase\n",
        "\n",
        "        val_inds = np.arange(len(x_val))\n",
        "\n",
        "        val_iters_per_epoch = int(np.ceil(1.0 * len(x_val) / batch_size))\n",
        "\n",
        "        epoch_validation_loss = 0\n",
        "        val_true_positive = 0\n",
        "\n",
        "\n",
        "        # iterating over the whole training set\n",
        "        for iter in range(val_iters_per_epoch):\n",
        "\n",
        "            val_batch_inds = val_inds[iter * batch_size: min(len(val_inds), (iter + 1) * batch_size)]\n",
        "\n",
        "            # reshaping placeholders\n",
        "            if len(val_batch_inds) != len(batch_x_placeholder):\n",
        "                batch_x_placeholder.resize_([len(val_batch_inds), 1, 28, 28])\n",
        "                batch_y_placeholder.resize_([len(val_batch_inds)])\n",
        "\n",
        "            batch_x_placeholder.copy_(torch.Tensor(x_val[val_batch_inds, np.newaxis, :, :]))\n",
        "            batch_y_placeholder.copy_(torch.Tensor(y_val[val_batch_inds].astype(int)))\n",
        "\n",
        "            b_decision, b_loss = model(batch_x_placeholder, batch_y_placeholder)\n",
        "            b_decision = b_decision.cpu().numpy()\n",
        "        \n",
        "            epoch_validation_loss += float(b_loss) / val_iters_per_epoch  # CARE: WE SHOULD USE FLOAT OVER LOSS\n",
        "            val_true_positive += np.sum(y_val[val_batch_inds].astype(int) == b_decision)\n",
        "                \n",
        "        epoch_validation_accuracy = val_true_positive * 100.0 / len(x_val)\n",
        "        val_loss[e] = epoch_validation_loss\n",
        "        val_acc[e] = epoch_validation_accuracy\n",
        "        # TO Complete\n",
        "    \n",
        "    print(f'Train epoch Loss: {epoch_loss:.4f}, train accuracy: {epoch_train_accuracy:.2f}, Validation Loss: {epoch_validation_loss:.4f}, validation accuracy: {epoch_validation_accuracy:.2f}')\n",
        "\n",
        "    # Saving the model and optimizer state\n",
        "    torch.save({\n",
        "            'epoch': e,\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'train_loss': epoch_loss,\n",
        "            'train_accuracy': epoch_train_accuracy,\n",
        "            'validation_loss': epoch_validation_loss,\n",
        "            'validation_accuracy': epoch_validation_accuracy\n",
        "        }, 'epoch_%d_state.pt' % e)\n",
        "\n",
        "    print('Epoch %d ended in %.2f secs.' % (e, time() - t_start,))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}